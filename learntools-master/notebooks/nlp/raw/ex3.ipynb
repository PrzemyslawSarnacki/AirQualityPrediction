{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Language\n",
    "\n",
    "Embeddings are both conceptually clever and practically effective. \n",
    "\n",
    "So let's try them for the sentiment analysis model you built for the restaurant. Then you can find the most similar review in the data set given some example text. It's a task where you can easily judge for yourself how well the embeddings work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.nlp.ex3 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>stars</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Total bill for this horrible service? Over $8G...</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have to say that this office really has it t...</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Went in for a lunch. Steak sandwich was delici...</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Today was my second out of three sessions I ha...</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                text  stars  sentiment\n0  Total bill for this horrible service? Over $8G...    1.0          0\n1  I *adore* Travis at the Hard Rock&#39;s new Kelly ...    5.0          1\n2  I have to say that this office really has it t...    5.0          1\n3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n4  Today was my second out of three sessions I ha...    1.0          0"
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the large model to get the vectors\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "review_data = pd.read_csv('../input/nlp-course/yelp_ratings.csv')\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of loading some document vectors. \n",
    "\n",
    "Calculating 44,500 document vectors takes about 20 minutes, so we'll get only the first 100. To save time, we'll load pre-saved document vectors for the hands-on coding exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 300)"
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = review_data[:100]\n",
    "# We just want the vectors so we can turn off other models in the pipeline\n",
    "with nlp.disable_pipes():\n",
    "    vectors = np.array([nlp(review.text).vector for idx, review in reviews.iterrows()])\n",
    "    \n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a matrix of 100 rows and 300 columns. \n",
    "\n",
    "Why 100 rows?\n",
    "Because we have 1 row for each column.\n",
    "\n",
    "Why 300 columns?\n",
    "This is the same length as word vectors. See if you can figure out why document vectors have the same length as word vectors (some knowledge of linear algebra or vector math would be needed to figure this out)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and run the following cell to load in the rest of the document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all document vectors from file\n",
    "vectors = np.load('../input/nlp-course/review_vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Training a Model on Document Vectors\n",
    "\n",
    "Next you'll train a `LinearSVC` model using the document vectors. It runs pretty quick and works well in high dimensional settings like you have here.\n",
    "\n",
    "After running the LinearSVC model, you might try experimenting with other types of models to see whether it improves your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 93.847%\n"
     ]
    },
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_TrainAModel\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc33\">Correct</span>",
      "text/plain": "Correct"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, review_data.sentiment, \r\n",
    "                                                    test_size=0.1, random_state=1)\r\n",
    "\r\n",
    "# Create the LinearSVC model\r\n",
    "model = LinearSVC(random_state=1, dual=False)\r\n",
    "# Fit the model\r\n",
    "model.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Uncomment and run to see model accuracy\r\n",
    "print(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')\r\n",
    "\r\n",
    "# Uncomment to check your work\r\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"1_TrainAModel\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> Create the LinearSVC model with the regularization parameter = 10, the random state set to 1, and dual set to False. Then fit the model with the training features and labels.",
      "text/plain": "Hint: Create the LinearSVC model with the regularization parameter = 10, the random state set to 1, and dual set to False. Then fit the model with the training features and labels."
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"1_TrainAModel\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n    model = LinearSVC(random_state=1, dual=False)\n    model.fit(X_train, y_train)\n    \n```",
      "text/plain": "Solution: \n```python\n\n    model = LinearSVC(random_state=1, dual=False)\n    model.fit(X_train, y_train)\n    \n```"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 68.111%\n"
     ]
    }
   ],
   "source": [
    "# Scratch space in case you want to experiment with other models\r\n",
    "from sklearn.naive_bayes import GaussianNB  \r\n",
    "\r\n",
    "second_model = GaussianNB()\r\n",
    "second_model.fit(X_train, y_train)\r\n",
    "print(f'Model test accuracy: {second_model.score(X_test, y_test)*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity\n",
    "\n",
    "For the same tea house review, find the most similar review in the dataset using cosine similarity.\n",
    "\n",
    "# 2) Centering the Vectors\n",
    "\n",
    "Sometimes people center document vectors when calculating similarities. That is, they calculate the mean vector from all documents, and they subtract this from each individual document's vector. Why do you think this could help with similarity metrics?\n",
    "\n",
    "Run the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"2_CenteringVectors\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n    Sometimes your documents will already be fairly similar. For example, this data set\n    is all reviews of businesses. There will be stong similarities between the documents\n    compared to news articles, technical manuals, and recipes. You end up with all the\n    similarities between 0.8 and 1 and no anti-similar documents (similarity < 0). When the\n    vectors are centered, you are comparing documents within your dataset as opposed to all\n    possible documents.\n    ",
      "text/plain": "Solution: \n    Sometimes your documents will already be fairly similar. For example, this data set\n    is all reviews of businesses. There will be stong similarities between the documents\n    compared to news articles, technical manuals, and recipes. You end up with all the\n    similarities between 0.8 and 1 and no anti-similar documents (similarity &lt; 0). When the\n    vectors are centered, you are comparing documents within your dataset as opposed to all\n    possible documents.\n    "
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Find the most similar review\n",
    "\n",
    "Given an example review below, find the most similar document within the Yelp dataset using the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3_SimilarReview\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc33\">Correct</span>",
      "text/plain": "Correct"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review = \"\"\"I absolutely love this place. The 360 degree glass windows with the \r\n",
    "Yerba buena garden view, tea pots all around and the smell of fresh tea everywhere \r\n",
    "transports you to what feels like a different zen zone within the city. I know \r\n",
    "the price is slightly more compared to the normal American size, however the food \r\n",
    "is very wholesome, the tea selection is incredible and I know service can be hit \r\n",
    "or miss often but it was on point during our most recent visit. Definitely recommend!\r\n",
    "\r\n",
    "I would especially recommend the butternut squash gyoza.\"\"\"\r\n",
    "\r\n",
    "def cosine_similarity(a, b):\r\n",
    "    return np.dot(a, b)/np.sqrt(a.dot(a)*b.dot(b))\r\n",
    "\r\n",
    "review_vec = nlp(review).vector\r\n",
    "\r\n",
    "## Center the document vectors\r\n",
    "# Calculate the mean for the document vectors, should have shape (300,)\r\n",
    "vec_mean = vectors.mean(axis=0)\r\n",
    "# Subtract the mean from the vectors\r\n",
    "centered = vectors - vec_mean\r\n",
    "\r\n",
    "# Calculate similarities for each document in the dataset\r\n",
    "# Make sure to subtract the mean from the review vector\r\n",
    "sims = np.array([cosine_similarity(review_vec - vec_mean, vec) for vec in centered])\r\n",
    "\r\n",
    "# Get the index for the most similar document\r\n",
    "most_similar = sims.argmax()\r\n",
    "\r\n",
    "# Uncomment to check your work\r\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"questionId\": \"3_SimilarReview\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> To get the correct mean vector, you'll need to set the `axis` keyword argument to take the mean over the rows (dimension 0). The mean vector should be the same shape as the other document vectors, a 300-element vector. From there you can iterate through each centered vector and calculate the cosine simularity with the tea house review's vector. Finally to get the index of the most similar review, the `.argmax()` method is useful.",
      "text/plain": "Hint: To get the correct mean vector, you&#39;ll need to set the `axis` keyword argument to take the mean over the rows (dimension 0). The mean vector should be the same shape as the other document vectors, a 300-element vector. From there you can iterate through each centered vector and calculate the cosine simularity with the tea house review&#39;s vector. Finally to get the index of the most similar review, the `.argmax()` method is useful."
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"questionId\": \"3_SimilarReview\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n    review_vec = nlp(review).vector\n\n    ## Center the document vectors\n    # Calculate the mean for the document vectors\n    vec_mean = vectors.mean(axis=0)\n    # Subtract the mean from the vectors\n    centered = vectors - vec_mean\n\n    # Calculate similarities for each document in the dataset\n    # Make sure to subtract the mean from the review vector\n    sims = np.array([cosine_similarity(review_vec - vec_mean, vec) for vec in centered])\n\n    # Get the index for the most similar document\n    most_similar = sims.argmax()\n    \n```",
      "text/plain": "Solution: \n```python\n\n    review_vec = nlp(review).vector\n\n    ## Center the document vectors\n    # Calculate the mean for the document vectors\n    vec_mean = vectors.mean(axis=0)\n    # Subtract the mean from the vectors\n    centered = vectors - vec_mean\n\n    # Calculate similarities for each document in the dataset\n    # Make sure to subtract the mean from the review vector\n    sims = np.array([cosine_similarity(review_vec - vec_mean, vec) for vec in centered])\n\n    # Get the index for the most similar document\n    most_similar = sims.argmax()\n    \n```"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After purchasing my final christmas gifts at the Urban Tea Merchant in Vancouver, I was surprised to hear about Teopia at the new outdoor mall at Don Mills and Lawrence when I went back home to Toronto for Christmas.\n",
      "Across from the outdoor skating rink and perfect to sit by the ledge to people watch, the location was prime for tea connesieurs... or people who are just freezing cold in need of a drinK!\n",
      "Like any gourmet tea shop, there were large tins of tea leaves on the walls, and although the tea menu seemed interesting enough, you can get any specialty tea as your drink. We didn&#39;t know what to get... so the lady suggested the Goji Berries... it smelled so succulent and juicy... instantly SOLD! I got it into a tea latte and watched the tea steep while the milk was steamed, and surprisingly, with the click of a button, all the water from the tea can be instantly drained into the cup (see photo).. very fascinating!\n",
      "\n",
      "The tea was aromatic and tasty, not over powering. The price was also very reasonable and I recommend everyone to get a taste of this place :)\n"
     ]
    }
   ],
   "source": [
    "print(review_data.iloc[most_similar].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there are many different sorts of businesses in our Yelp dataset, you should have found another tea shop. \n",
    "\n",
    "# 4) Looking at similar reviews\n",
    "\n",
    "If you look at other similar reviews, you'll see many coffee shops. Why do you think reviews for coffee are similar to the example review which mentions only tea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"4_OtherSimilarReviews\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": "&lt;IPython.core.display.Javascript object&gt;"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n    Reviews for coffee shops will also be similar to our tea house review because\n    coffee and tea are semantically similar. Most cafes serve both coffee and tea\n    so you'll see the terms appearing together often.\n    ",
      "text/plain": "Solution: \n    Reviews for coffee shops will also be similar to our tea house review because\n    coffee and tea are semantically similar. Most cafes serve both coffee and tea\n    so you&#39;ll see the terms appearing together often.\n    "
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've finished the NLP course. It's an exciting field that will help you make use of vast amounts of data you didn't know how to work with before.\n",
    "\n",
    "This course should be just your introduction. Try a project **[with text](https://www.kaggle.com/datasets?tags=14104-text+data)**. You'll have fun with it, and your skills will continue growing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "c72aa234833b301e2f3682b00c720ead16def47389b468b3b25c2ea5dfc1217d"
    }
   },
   "name": "Python 3.8.2 64-bit ('.venv')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}