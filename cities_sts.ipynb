{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cities_sts.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit ('.venv')",
      "metadata": {
        "interpreter": {
          "hash": "c72aa234833b301e2f3682b00c720ead16def47389b468b3b25c2ea5dfc1217d"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B152vZs3jUwt"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrzemyslawSarnacki/AirQualityPrediction/blob/master/cities_sts.ipynb\" target=\"_parent\">\r\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\r\n",
        "</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROOmrQI5jUww"
      },
      "source": [
        "## Wstępna obróbka danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_VRxhtAjUwy",
        "tags": []
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import warnings\r\n",
        "import numpy as np\r\n",
        "import unicodedata\r\n",
        "from io import BytesIO\r\n",
        "import requests\r\n",
        "import joblib\r\n",
        "\r\n",
        "\r\n",
        "warnings.simplefilter('ignore')\r\n",
        "sns.set_style('darkgrid', {'axes.facecolor': '.9'})\r\n",
        "sns.set_palette(palette='deep')\r\n",
        "sns_c = sns.color_palette(palette='deep')\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from pandas.plotting import register_matplotlib_converters\r\n",
        "register_matplotlib_converters()\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "\r\n",
        "def strip_accents(text):\r\n",
        "    return ''.join(c for c in unicodedata.normalize('NFKD', text.lower().replace(\"ł\",\"l\")) if unicodedata.category(c) != 'Mn')\r\n",
        "\r\n",
        "CITIES = [\"Warszawa\", \"Kraków\", \"Poznań\", \"Katowice\", \"Białystok\"]\r\n",
        "COORDINATES = {\r\n",
        "    \"warszawa\": {\r\n",
        "        \"latitude\": 52.2297,\r\n",
        "        \"longitude\": 21.0122\r\n",
        "    },\r\n",
        "    \"krakow\": {\r\n",
        "        \"latitude\": 50.0647,\r\n",
        "        \"longitude\": 19.9450\r\n",
        "    },\r\n",
        "    \"poznan\": {\r\n",
        "        \"latitude\": 52.4064,\r\n",
        "        \"longitude\": 16.9252\r\n",
        "    },\r\n",
        "    \"katowice\": {\r\n",
        "        \"latitude\": 50.2649,\r\n",
        "        \"longitude\": 19.0238\r\n",
        "    },\r\n",
        "    \"bialystok\": {\r\n",
        "        \"latitude\": 53.1325,\r\n",
        "        \"longitude\": 23.1688\r\n",
        "    },\r\n",
        "}\r\n",
        "PARAMETERS = ['pm25', 'pm10', 'no2', 'so2', 'o3', 'co']\r\n",
        "\r\n",
        "indices = [\"\"] + [f\".{i}\" for i in range(1, 6)]\r\n",
        "data = {}\r\n",
        "\r\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/PrzemyslawSarnacki/AirQualityPrediction/master/data/airq_data_2.csv\", index_col=0, parse_dates=True)\r\n",
        "\r\n",
        "# load machine learning model for aqi prediction\r\n",
        "m_link = 'https://github.com/PrzemyslawSarnacki/AirQualityPrediction/blob/master/data/aqi.joblib?raw=true'\r\n",
        "m_file = BytesIO(requests.get(m_link).content)\r\n",
        "aqi_model = joblib.load(m_file)\r\n",
        "\r\n",
        "# fill columns with data\r\n",
        "for city in CITIES:\r\n",
        "    data[strip_accents(city)] = pd.DataFrame(df, columns=[f\"{strip_accents(city)}{item}\" for item in indices])\r\n",
        "    data[strip_accents(city)] = data[strip_accents(city)].rename(columns=data[strip_accents(city)].iloc[0]).drop(data[strip_accents(city)].index[0])\r\n",
        "    data[strip_accents(city)] = data[strip_accents(city)].astype(float).interpolate(method=\"linear\")\r\n",
        "    data[strip_accents(city)].index = pd.to_datetime(data[strip_accents(city)].index)\r\n",
        "    data[strip_accents(city)][\"aqi\"] = aqi_model.predict(data[strip_accents(city)].fillna(0))\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhVTOks-R-5A"
      },
      "source": [
        "from datetime import timedelta\r\n",
        "\r\n",
        "last_date = data[strip_accents(CITIES[-1])].index[-1]\r\n",
        "last_date_str = last_date.strftime(\"%Y-%m-%d\")\r\n",
        "\r\n",
        "half_year_date = last_date + timedelta(days=173) \r\n",
        "half_year_date_str = half_year_date.strftime(\"%Y-%m-%d\")\r\n",
        "date_range = pd.date_range(start=last_date_str, end=half_year_date_str, freq='D')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFXEgyqe27M"
      },
      "source": [
        "# Definicja funkcji "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y02uoM2cuncC"
      },
      "source": [
        "def create_s_features(data, city, date_range):\r\n",
        "  data[city] = data[city].append(pd.DataFrame(index=date_range))\r\n",
        "  # create columns with seasonal features\r\n",
        "  data[city]['day_of_month'] = data[city].index.day\r\n",
        "  data[city]['month'] = data[city].index.month\r\n",
        "  data[city]['day_of_week'] = data[city].index.dayofweek\r\n",
        "  data[city]['daysinmonth'] = data[city].index.daysinmonth\r\n",
        "  return data\r\n",
        "\r\n",
        "def create_external_regressor(data, city):\r\n",
        "  external = data[city]['aqi'].copy()\r\n",
        "  one_year_aqi = data[city]['aqi'].head(365).copy()\r\n",
        "  # delete unexpected values\r\n",
        "  one_year_aqi[66:68] = [60, 70]\r\n",
        "  observed_years_num = len(data[city]) / 365\r\n",
        "  remainder =  observed_years_num % 1\r\n",
        "  integer = observed_years_num - remainder \r\n",
        "  for i in range(1, int(integer + 1)):\r\n",
        "    external[365*(i-1):365*i] = one_year_aqi\r\n",
        "\r\n",
        "  external[365*i::] = one_year_aqi[:(round(remainder*365))]\r\n",
        "  return external\r\n",
        "\r\n",
        "def split_data(data, last_date_str, city, external):\r\n",
        "  # split data for training and test \r\n",
        "  threshold_date = pd.to_datetime(last_date_str)\r\n",
        "  mask = data[city].index < threshold_date\r\n",
        "  df_train = data[city][mask]\r\n",
        "  df_test = data[city][~ mask]\r\n",
        "  df_test['aqi'] = external[~mask]\r\n",
        "  df_train[\"date\"] = df_train.index\r\n",
        "  return df_train, df_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og-6xRcGsDdk"
      },
      "source": [
        "def create_model(data, df_train, df_test, city, external):\r\n",
        "  # Local linear trend. \r\n",
        "  local_linear_trend = tfp.sts.LocalLinearTrend(\r\n",
        "      observed_time_series=df_train['aqi'].astype(np.float32), \r\n",
        "      name='local_linear_trend',\r\n",
        "  )\r\n",
        "\r\n",
        "  # We need to pre-define the number of days in each month.\r\n",
        "  num_days_per_month = np.array(\r\n",
        "    [\r\n",
        "      [31, 28, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31],\r\n",
        "      [31, 28, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31],\r\n",
        "      [31, 29, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31] # year with leap day.\r\n",
        "    ] \r\n",
        "  )  \r\n",
        "\r\n",
        "  # Define month of year seasonal variable.\r\n",
        "  month_of_year = tfp.sts.Seasonal(\r\n",
        "    num_seasons=12,\r\n",
        "    num_steps_per_season=num_days_per_month,\r\n",
        "    name='month_of_year'\r\n",
        "  )\r\n",
        "\r\n",
        "  # Define day of week as seasonal variable.\r\n",
        "  day_of_week = tfp.sts.Seasonal(\r\n",
        "      num_seasons=7,\r\n",
        "      num_steps_per_season=1,\r\n",
        "      observed_time_series=df_train['aqi'].astype(np.float32), \r\n",
        "      name='day_of_week',\r\n",
        "  )\r\n",
        "\r\n",
        "  # Create cyclic variable for day of the month.\r\n",
        "  design_matrix_day_of_month = tf.reshape(\r\n",
        "      np.sin(2*np.pi*data[city]['day_of_month'] / data[city]['daysinmonth']).values.astype(np.float32), \r\n",
        "      (-1, 1)\r\n",
        "  )\r\n",
        "\r\n",
        "  # Define day of the month as an external regressor.\r\n",
        "  # We do not encode it as seasonal as the number of steps is not uniform.\r\n",
        "  day_of_month = tfp.sts.LinearRegression(\r\n",
        "      design_matrix=design_matrix_day_of_month,\r\n",
        "      name='day_of_month'\r\n",
        "  )\r\n",
        "\r\n",
        "  # Define external regressor component. \r\n",
        "  # We use the whole data set (df) as we expect to have these values in the future. \r\n",
        "  design_matrix_x_var = tf.reshape(external.astype(np.float32), (-1, 1))\r\n",
        "\r\n",
        "  x_var = tfp.sts.LinearRegression(\r\n",
        "      design_matrix=design_matrix_x_var,\r\n",
        "      name='x_var'\r\n",
        "  )\r\n",
        "\r\n",
        "  model_components = [\r\n",
        "      local_linear_trend, \r\n",
        "      month_of_year, \r\n",
        "      day_of_week, \r\n",
        "      day_of_month, \r\n",
        "      x_var,\r\n",
        "  ]\r\n",
        "\r\n",
        "  toy_model = tfp.sts.Sum(\r\n",
        "      components=model_components, \r\n",
        "      observed_time_series=df_train['aqi'].astype(np.float32)\r\n",
        "      )\r\n",
        "  return toy_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EGT4l0kXav0"
      },
      "source": [
        "W tym momencie wygenerujemy prognozę Air Quality Index dla ostatnich 6 miesięcy roku 2020 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSNqZBwNx9rw"
      },
      "source": [
        "def predict(df_train, df_test, toy_model, variational_posteriors):\r\n",
        "  num_days_per_month = np.array(\r\n",
        "    [\r\n",
        "      [31, 28, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31],\r\n",
        "      [31, 28, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31],\r\n",
        "      [31, 29, 31, 30, 30, 31, 31, 31, 30, 31, 30, 31] # year with leap day.\r\n",
        "    ] \r\n",
        "  )  \r\n",
        "  q_samples = variational_posteriors.sample(1000)\r\n",
        "  num_parameters = len(toy_model.parameters)\r\n",
        "\r\n",
        "  # Compute number of days in the last 6 months of 2020.\r\n",
        "  forecast_window = num_days_per_month[-1][6:13].sum() - 9\r\n",
        "\r\n",
        "  # Get forecast distribution.\r\n",
        "  forecast_dist = tfp.sts.forecast(\r\n",
        "      toy_model,\r\n",
        "      observed_time_series=df_train['aqi'].astype(np.float32),\r\n",
        "      parameter_samples=q_samples,\r\n",
        "      num_steps_forecast=forecast_window.astype(np.int32)\r\n",
        "  )\r\n",
        "  # Sample and compute mean and std. \r\n",
        "  num_samples = 100\r\n",
        "\r\n",
        "  forecast_mean, forecast_scale, forecast_samples = (\r\n",
        "      forecast_dist.mean().numpy().flatten(),\r\n",
        "      forecast_dist.stddev().numpy().flatten(),\r\n",
        "      forecast_dist.sample(num_samples).numpy().flatten()\r\n",
        "  )\r\n",
        "\r\n",
        "  df_test['y_pred'] = forecast_mean\r\n",
        "  df_test['y_pred_std'] = forecast_scale\r\n",
        "  df_test['errors'] = df_test['aqi'] - df_test['y_pred']\r\n",
        "  return df_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RmWVyJ2yS16"
      },
      "source": [
        "def run_city_prediction(data, city):\r\n",
        "  data = create_s_features(data, city, date_range)\r\n",
        "  external = create_external_regressor(data, city)\r\n",
        "  df_train, df_test = split_data(data, last_date_str, city, external)\r\n",
        "  toy_model = create_model(data, df_train, df_test, city, external)\r\n",
        "  variational_posteriors = tfp.sts.build_factored_surrogate_posterior(model=toy_model, seed=42)\r\n",
        "  q_prior_samples = variational_posteriors.sample(1000)\r\n",
        "  # Set optimizer.\r\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.1)\r\n",
        "\r\n",
        "  # Using fit_surrogate_posterior to build and optimize \r\n",
        "  # the variational loss function.\r\n",
        "  @tf.function(experimental_compile=True)\r\n",
        "  def train():\r\n",
        "      # Build the joint density. \r\n",
        "      num_variational_steps = int(200)\r\n",
        "      target_log_prob_fn = toy_model.joint_log_prob(\r\n",
        "          observed_time_series=df_train['aqi'].astype(np.float32)\r\n",
        "      )\r\n",
        "      \r\n",
        "      elbo_loss_curve = tfp.vi.fit_surrogate_posterior(\r\n",
        "          target_log_prob_fn=target_log_prob_fn,\r\n",
        "          surrogate_posterior=variational_posteriors,\r\n",
        "          optimizer=optimizer,\r\n",
        "          num_steps=num_variational_steps,\r\n",
        "          seed=42\r\n",
        "      )\r\n",
        "      \r\n",
        "      return elbo_loss_curve\r\n",
        "\r\n",
        "  # Run optimization.\r\n",
        "  elbo_loss_curve = train()\r\n",
        "  df_test = predict(df_train, df_test, toy_model, variational_posteriors)\r\n",
        "  return df_train, df_test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44fAcc9m4vOv"
      },
      "source": [
        "# Białystok\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc5e1VJjyXiF"
      },
      "source": [
        "df_train, df_test = run_city_prediction(data, strip_accents(CITIES[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHQJHD5sDhHV"
      },
      "source": [
        "threshold_date = pd.to_datetime(last_date_str)\r\n",
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='y_train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='y_test', data=df_test, ax=ax)\r\n",
        "ax.axvline(threshold_date, color=sns_c[3], linestyle='--', label='train test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='Dependent Variable');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcKV-YIJX7yB"
      },
      "source": [
        "Przedstawmy wynik naszego modelu na wykresie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3gyqZMwyaV9"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='test', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.axvline(x= threshold_date, color=sns_c[3], linestyle='--', label='train-test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui_1kY3sYcr-"
      },
      "source": [
        "Okres przewidywany z danymi rzeczywistymi w przybliżeniu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f7NErW93eGF"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='prediction', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9oSUopaZR3F"
      },
      "source": [
        "Przedstawienie korelacji między predykcjami, a wartościami rzeczywistymi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPT_azWzFZSp"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\r\n",
        "\r\n",
        "# Generate diagonal line to plot. \r\n",
        "d_x = np.linspace(start=df_test['aqi'].min() - 1, stop=df_test['aqi'].max() + 1, num=100)\r\n",
        "sns.regplot(x='aqi', y='y_pred', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=d_x, y=d_x, dashes={'linestyle': ''}, ax=ax)\r\n",
        "ax.lines[1].set_linestyle('--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJiXlO7dAL9"
      },
      "source": [
        "Sprawdźmy jak wyglądają poszczególne błędy modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2Gw9VsLVdo"
      },
      "source": [
        "Błąd średniokwadratowy (Mean Squared Error):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_zVnNPXLdfV"
      },
      "source": [
        "np.square(df_test[\"errors\"]).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSc8m0gBpkqX"
      },
      "source": [
        "Jak widzimy błędy mają postać rozkładu Rayleigha i większość błędów skupia się wokół wartości -40 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQlSn-uFa_XN"
      },
      "source": [
        "errors_mean = df_test['errors'].mean()\r\n",
        "errors_std = df_test['errors'].std()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCuNWSXIgZ_q"
      },
      "source": [
        "errors_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwwYfq0ScFu1"
      },
      "source": [
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "sns.scatterplot(x='index', y='errors', data=df_test.reset_index(), ax=ax)\r\n",
        "ax.axhline(y=errors_mean, color=sns_c[2], linestyle='--', label=r'$\\mu$ ')\r\n",
        "ax.axhline(y=errors_mean + 2*errors_std, color=sns_c[3], linestyle='--', label=r'$\\mu \\pm 2\\sigma$')\r\n",
        "ax.axhline(y=errors_mean - 2*errors_std, color=sns_c[3], linestyle='--')\r\n",
        "ax.legend()\r\n",
        "ax.set(title='Model Errors (Test Set)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yuEbeHVV15h"
      },
      "source": [
        "# Warszawa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo1Fbv8GV5VB"
      },
      "source": [
        "df_train, df_test = run_city_prediction(data, strip_accents(CITIES[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZsxZjuTWDu0"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='test', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.axvline(x= threshold_date, color=sns_c[3], linestyle='--', label='train-test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89-lQ_4JaSNC"
      },
      "source": [
        "# Kraków"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHfbL70BaEwW"
      },
      "source": [
        "df_train, df_test = run_city_prediction(data, strip_accents(CITIES[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3mh3q66aIPR"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='test', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.axvline(x= threshold_date, color=sns_c[3], linestyle='--', label='train-test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z524_wHbevr"
      },
      "source": [
        "# Poznań"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZNmlmRYbYCV"
      },
      "source": [
        "df_train, df_test = run_city_prediction(data, strip_accents(CITIES[2]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMIy6rQqbanb"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='test', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.axvline(x= threshold_date, color=sns_c[3], linestyle='--', label='train-test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynN7i2_kbhL8"
      },
      "source": [
        "# Katowice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzbBwFxpblaP"
      },
      "source": [
        "df_train, df_test = run_city_prediction(data, strip_accents(CITIES[3]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLsGCAR-bovC"
      },
      "source": [
        "fig, ax = plt.subplots(figsize= (12, 10))\r\n",
        "\r\n",
        "ax.fill_between(\r\n",
        "    x=df_test.index,\r\n",
        "    y1=df_test['y_pred']-2*df_test['y_pred_std'],\r\n",
        "    y2=df_test['y_pred']+2*df_test['y_pred_std'],\r\n",
        "    color=sns_c[2], \r\n",
        "    alpha=0.25,\r\n",
        "    label=r'credible_interval ($\\mu \\pm 2\\sigma$)'\r\n",
        ")\r\n",
        "\r\n",
        "sns.lineplot(x=df_train.index, y='aqi', label='train', data=df_train, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='aqi', label='test', data=df_test, ax=ax)\r\n",
        "sns.lineplot(x=df_test.index, y='y_pred', label='prediction', data=df_test, ax=ax)\r\n",
        "ax.axvline(x= threshold_date, color=sns_c[3], linestyle='--', label='train-test split')\r\n",
        "ax.legend(loc='upper left')\r\n",
        "ax.set(title='STS Forecast');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uN-cYGZsuvL"
      },
      "source": [
        "# Pobieranie predykcji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xJTQDPssQ0Z",
        "outputId": "873edc56-9bd1-416c-ddf1-1da91d0801ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir predictions"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘predictions’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Ycj9WTn5ey",
        "outputId": "6be36950-bbfc-48d4-9615-18c8cb94debb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_path = \"/content/predictions/\"\r\n",
        "for city in CITIES:\r\n",
        "  df_train, df_test = run_city_prediction(data, strip_accents(city))\r\n",
        "  df_train[-50::]['aqi'].to_csv(f\"{pred_path}prediction-{strip_accents(city)}.csv\")\r\n",
        "  df_test[['y_pred', 'y_pred_std', 'errors']][:50].to_csv(f\"{pred_path}history-{strip_accents(city)}.csv\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_composition.py:181: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not call `graph_parents`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/distributions/distribution.py:298: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
            "Instructions for updating:\n",
            "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:175: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function run_city_prediction.<locals>.train at 0x7f6f319c2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSGdK_Y-tqMk",
        "outputId": "3fed8fc0-b6ca-4d03-8066-fa4aa8d443f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!zip -r predictions.zip predictions"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions/ (stored 0%)\n",
            "  adding: predictions/history-warszawa.csv (deflated 54%)\n",
            "  adding: predictions/prediction-bialystok.csv (deflated 72%)\n",
            "  adding: predictions/prediction-poznan.csv (deflated 73%)\n",
            "  adding: predictions/history-poznan.csv (deflated 53%)\n",
            "  adding: predictions/prediction-krakow.csv (deflated 77%)\n",
            "  adding: predictions/prediction-warszawa.csv (deflated 74%)\n",
            "  adding: predictions/history-katowice.csv (deflated 53%)\n",
            "  adding: predictions/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: predictions/prediction-katowice.csv (deflated 79%)\n",
            "  adding: predictions/history-bialystok.csv (deflated 54%)\n",
            "  adding: predictions/history-krakow.csv (deflated 54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcc-w2jPu1lW",
        "outputId": "ba8ddc73-be66-42e2-97e1-a50b85a760f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download('predictions.zip') "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7dddc28c-fe66-48ca-b809-78427458a6c8\", \"predictions.zip\", 9841)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}